{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "83f1ffe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Label                                               Text\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5568   ham               Will ü b going to esplanade fr home?\n",
       "5569   ham  Pity, * was in mood for that. So...any other s...\n",
       "5570   ham  The guy did some bitching but I acted like i'd...\n",
       "5571   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('SMSSpamCollection', sep='\\t', header=None, names=['Label', 'Text'])\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18603309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     4825\n",
      "spam     747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"Label\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebcac424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label\n",
      "ham     747\n",
      "spam    747\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "def create_balanced_dataset(df):\n",
    "\tnum_spam = df[df['Label'] == 'spam'].shape[0]\n",
    "\thum_subset = df[df['Label'] == 'ham'].sample(num_spam, random_state=123)\n",
    "\tbalanced_df = pd.concat([hum_subset, df[df['Label'] == 'spam']])\n",
    "\treturn balanced_df\n",
    "\n",
    "balanced_df = create_balanced_dataset(df)\n",
    "print(balanced_df[\"Label\"].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "59d8026a",
   "metadata": {},
   "outputs": [],
   "source": [
    "balanced_df[\"Label\"] = balanced_df[\"Label\"].map({'ham': 0, 'spam': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a5497ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_split(df, train_ratio, validation_ratio):\n",
    "\t\n",
    "\tdf = df.sample(frac=1, random_state=123).reset_index(drop=True)\n",
    "\ttrain_end = int(train_ratio * len(df))\n",
    "\tvalidation_end = int((train_ratio + validation_ratio) * len(df))\n",
    "\t\n",
    "\ttrain_df = df[:train_end]\n",
    "\tvalidation_df = df[train_end:validation_end]\n",
    "\ttest_df = df[validation_end:]\n",
    "\t\n",
    "\treturn train_df, validation_df, test_df\n",
    "\n",
    "train_df, validation_df, test_df = random_split(balanced_df, 0.7, 0.1)\n",
    "\n",
    "train_df.to_csv('train.csv', index=None)\n",
    "validation_df.to_csv('validation.csv', index=None)\n",
    "test_df.to_csv('test.csv', index=None)\n",
    "\n",
    "\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3151f7f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50256]\n"
     ]
    }
   ],
   "source": [
    "import tiktoken\n",
    "\n",
    "tokenizer = tiktoken.get_encoding(\"gpt2\")\n",
    "\n",
    "print(tokenizer.encode(\"<|endoftext|>\", allowed_special={\"<|endoftext|>\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c7845e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "class SpamDataset(Dataset):\n",
    "\tdef __init__(self, csv_file, tokenizer, max_length=None, pad_token_id=50256):\n",
    "\t\tself.data = pd.read_csv(csv_file)\n",
    "\t\t\n",
    "\t\tself.encoded_texts = [\n",
    "\t\t\ttokenizer.encode(text) for text in self.data[\"Text\"]\n",
    "\t\t]\n",
    "\t\t\n",
    "\t\tif max_length is None:\n",
    "\t\t\tself.max_length = max(len(text) for text in self.encoded_texts)\n",
    "\t\telse:\n",
    "\t\t\tself.max_length = max_length\n",
    "\t\t\t\n",
    "\t\tself.encoded_texts = [\n",
    "\t\t\ttext[:self.max_length] + [pad_token_id] * (self.max_length - len(text))\n",
    "\t\t\tfor text in self.encoded_texts\n",
    "\t\t]\n",
    "\t\t\n",
    "\tdef __len__(self):\n",
    "\t\treturn len(self.encoded_texts)\n",
    "\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\tencoded = self.encoded_texts[idx]\n",
    "\t\tlabel = self.data.iloc[idx][\"Label\"]\n",
    "\t\treturn torch.tensor(encoded, dtype=torch.long), torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "\tdef _longest_encoded_length(self):\n",
    "\t\tmax_length = max(len(text) for text in self.encoded_texts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9590302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n"
     ]
    }
   ],
   "source": [
    "train_dataset = SpamDataset(\"train.csv\", tokenizer, max_length=128)\n",
    "# validation_dataset = SpamDataset(\"validation.csv\", tokenizer, max_length=128)\n",
    "\n",
    "print(train_dataset.max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ae780b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = SpamDataset(\"validation.csv\", tokenizer, max_length=train_dataset.max_length)\n",
    "test_dataset = SpamDataset(\"test.csv\", tokenizer, max_length=train_dataset.max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "336f722c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "num_workers = 0\n",
    "batch_size = 8\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_loader = DataLoader(\n",
    "\ttrain_dataset, \n",
    "\tbatch_size=batch_size, \n",
    "\tshuffle=True, \n",
    "\tnum_workers=num_workers,\n",
    "\tdrop_last=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "\tval_dataset, \n",
    "\tbatch_size=batch_size, \n",
    "\tshuffle=False, \n",
    "\tnum_workers=num_workers,\n",
    "\tdrop_last=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "\ttest_dataset, \n",
    "\tbatch_size=batch_size, \n",
    "\tshuffle=False, \n",
    "\tnum_workers=num_workers,\n",
    "\tdrop_last=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f363a98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch dimensions: torch.Size([8, 128])\n",
      "Labels batch dimensions: torch.Size([8])\n"
     ]
    }
   ],
   "source": [
    "for input_batch, target_batch in train_loader:\n",
    "\tpass\n",
    "print(\"Input batch dimensions:\", input_batch.shape)\n",
    "print(\"Labels batch dimensions:\", target_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b124ee8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "130 training batches\n",
      "18 validation batches\n",
      "37 test batches\n"
     ]
    }
   ],
   "source": [
    "print(f\"{len(train_loader)} training batches\")\n",
    "print(f\"{len(val_loader)} validation batches\")\n",
    "print(f\"{len(test_loader)} test batches\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a9c1372e",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHOOSE_MODEL = \"gpt2-small (124M)\"\n",
    "INPUT_PROMPT = \"Every effort moves\"\n",
    "\n",
    "BASE_CONFIG = {\n",
    "\t\"vocab_size\": 50257,\n",
    "\t\"context_length\": 1024,\n",
    "\t\"drop_rate\": 0.0,\n",
    "\t\"qkv_bias\": True,\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt2-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt2-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt2-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt2-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "BASE_CONFIG.update(model_configs[CHOOSE_MODEL])\n",
    "\n",
    "assert train_dataset.max_length <= BASE_CONFIG[\"context_length\"], (\n",
    "    f\"Dataset length {train_dataset.max_length} exceeds model's context \"\n",
    "    f\"length {BASE_CONFIG['context_length']}. Reinitialize data sets with \"\n",
    "    f\"`max_length={BASE_CONFIG['context_length']}`\"\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f644df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt_download import download_and_load_gpt2\n",
    "import import_ipynb\n",
    "from ch5 import GPTModel, load_weights_into_gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f42d338f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists and is up-to-date: gpt2/124M/checkpoint\n",
      "File already exists and is up-to-date: gpt2/124M/encoder.json\n",
      "File already exists and is up-to-date: gpt2/124M/hparams.json\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.data-00000-of-00001\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.index\n",
      "File already exists and is up-to-date: gpt2/124M/model.ckpt.meta\n",
      "File already exists and is up-to-date: gpt2/124M/vocab.bpe\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GPTModel(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.0, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (att): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_shortcut): Dropout(p=0.0, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_size = CHOOSE_MODEL.split(\" \")[-1].lstrip(\"(\").rstrip(\")\")\n",
    "settings, params = download_and_load_gpt2(model_size=model_size, models_dir=\"gpt2\")\n",
    "\n",
    "model = GPTModel(BASE_CONFIG)\n",
    "load_weights_into_gpt(model, params)\n",
    "model.eval()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a01389f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Every effort moves you forward.\n",
      "\n",
      "The first step is to understand the importance of your work\n"
     ]
    }
   ],
   "source": [
    "from ch4 import generate_text_simple\n",
    "from ch5 import text_to_token_ids, token_ids_to_text\n",
    "\n",
    "text1 = \"Every effort moves you\"\n",
    "token_ids = generate_text_simple(\n",
    "\tmodel, \n",
    "\tidx=text_to_token_ids(text1, tokenizer),\n",
    "\tmax_new_tokens=15,\n",
    "\tcontext_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1882c633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the following text 'spam'? Answer with 'yes' or 'no':\n",
      "You are the winner of the lottery\n",
      " selected to recieve a $1000 gift card.\n",
      "\n",
      "You are the winner of the lottery selected to receive a $\n"
     ]
    }
   ],
   "source": [
    "text2 = (\n",
    "\t\"Is the following text 'spam'? Answer with 'yes' or 'no':\\n\"\n",
    "\t\"You are the winner of the lottery\\n\"\n",
    "\t\" selected to recieve a $1000 gift card\"\n",
    ")\n",
    "token_ids = generate_text_simple(\n",
    "\tmodel, \n",
    "\tidx=text_to_token_ids(text2, tokenizer),\n",
    "\tmax_new_tokens=15,\n",
    "\tcontext_size=BASE_CONFIG[\"context_length\"]\n",
    ")\n",
    "print(token_ids_to_text(token_ids, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2564138d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We are going to replace the output layer with a binary classification head\n",
    "\n",
    "## Also to prepare for fine-tuning, we are going to freeze all the weights of the pre-trained model\n",
    "\n",
    "for param in model.parameters():\n",
    "\tparam.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6a959395",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Classification layer\n",
    "\n",
    "torch.manual_seed(123)\n",
    "num_classes = 2\n",
    "model.out_head = torch.nn.Linear(\n",
    "\tin_features=BASE_CONFIG[\"emb_dim\"], \n",
    "\tout_features=num_classes\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8e7bf5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make the last block and final norm layer trainable\n",
    "\n",
    "for param in model.trf_blocks[-1].parameters():\n",
    "\tparam.requires_grad = True\n",
    "for params in model.final_norm.parameters():\n",
    "\tparams.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "55467dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs: tensor([[5211,  345,  423,  640]])\n",
      "Inputs shape: torch.Size([1, 4])\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer.encode(\"Do you have time\")\n",
    "inputs = torch.tensor(inputs).unsqueeze(0)\n",
    "print(\"Inputs:\", inputs)\n",
    "print(\"Inputs shape:\", inputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9cfd60aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outputs shape: torch.Size([1, 4, 2])\n",
      "Outputs: tensor([[[-1.5854e+00,  9.9035e-01],\n",
      "         [-3.7235e+00,  7.4548e+00],\n",
      "         [-2.2661e+00,  6.6049e+00],\n",
      "         [-3.5983e+00,  3.9902e+00]]])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "\toutputs = model(inputs)\n",
    "print(\"Outputs shape:\", outputs.shape)\n",
    "print(\"Outputs:\", outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a0535fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last output token: tensor([[-3.5983e+00,  3.9902e+00]])\n"
     ]
    }
   ],
   "source": [
    "## The number of rows corresponds to the number of input tokens. We're only interested in the last row\n",
    "\n",
    "print(\"Last output token:\", outputs[:, -1, :])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f03ec202",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 1\n"
     ]
    }
   ],
   "source": [
    "probas = torch.softmax(outputs[:, -1, :], dim=-1)\n",
    "label = torch.argmax(probas)\n",
    "print(\"Label:\", label.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "747bacbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class label: 1\n"
     ]
    }
   ],
   "source": [
    "logits = outputs[:, -1, :]\n",
    "label = torch.argmax(logits)\n",
    "print(\"Class label:\", label.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1c11f739",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_accuracy_loader(data_loader, model, device, num_batches=None):\n",
    "\tmodel.eval()\n",
    "\ttotal_correct = 0\n",
    "\ttotal_samples = 0\n",
    "\n",
    "\tif num_batches is not None:\n",
    "\t\tnum_batches = min(num_batches, len(data_loader))\n",
    "\telse:\n",
    "\t\tnum_batches = len(data_loader)\n",
    "\t\n",
    "\tfor i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "\t\tif i < num_batches:\n",
    "\t\t\tinput_batch = input_batch.to(device)\n",
    "\t\t\ttarget_batch = target_batch.to(device)\n",
    "\n",
    "\t\t\twith torch.no_grad():\n",
    "\t\t\t\tlogits = model(input_batch)[:, -1, :]\n",
    "\t\t\t\tpredicted_class = torch.argmax(logits, dim=1)\n",
    "\t\t\t\ttotal_correct += (predicted_class == target_batch).sum().item()\n",
    "\t\t\t\ttotal_samples += predicted_class.shape[0]\n",
    "\n",
    "\t\telse:\n",
    "\t\t\tbreak\n",
    "\t\n",
    "\taccuracy = total_correct / total_samples\n",
    "\treturn accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d6d3b97c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.4625\n",
      "Validation accuracy: 0.4500\n",
      "Test accuracy: 0.4750\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "torch.manual_seed(123)\n",
    "\n",
    "train_accuracy = cal_accuracy_loader(train_loader, model, device, num_batches=10)\n",
    "val_accuracy = cal_accuracy_loader(val_loader, model, device, num_batches=10)\n",
    "test_accuracy = cal_accuracy_loader(test_loader, model, device, num_batches=10)\n",
    "\n",
    "print(f\"Train accuracy: {train_accuracy:.4f}\")\n",
    "print(f\"Validation accuracy: {val_accuracy:.4f}\")\n",
    "print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8151040b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_batch(input_batch, target_batch, model, device):\n",
    "\tinput_batch = input_batch.to(device)\n",
    "\ttarget_batch = target_batch.to(device)\n",
    "\n",
    "\tlogits = model(input_batch)[:, -1, :]\n",
    "\tloss = torch.nn.functional.cross_entropy(logits, target_batch)\n",
    "\treturn loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b001e781",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_loss_loader(data_loader, model, device, num_batches=None):\n",
    "\ttotal_loss = 0\n",
    "\tif len(data_loader) == 0:\n",
    "\t\treturn float('nan')\n",
    "\telif num_batches is None:\n",
    "\t\tnum_batches = len(data_loader)\n",
    "\telse:\n",
    "\t\tnum_batches = min(num_batches, len(data_loader))\n",
    "\t\n",
    "\tfor i, (input_batch, target_batch) in enumerate(data_loader):\n",
    "\t\tif i < num_batches:\n",
    "\t\t\tloss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "\t\t\ttotal_loss += loss.item()\n",
    "\t\telse:\n",
    "\t\t\tbreak\n",
    "\t\n",
    "\tavg_loss = total_loss / num_batches\n",
    "\treturn avg_loss\n",
    "\n",
    "\n",
    "\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5585116b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 2.9057\n",
      "Validation loss: 2.8386\n",
      "Test loss: 2.6986\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "\ttrain_loss = calc_loss_loader(train_loader, model, device, num_batches=10)\n",
    "\tval_loss = calc_loss_loader(val_loader, model, device, num_batches=10)\n",
    "\ttest_loss = calc_loss_loader(test_loader, model, device, num_batches=10)\n",
    "\n",
    "print(f\"Train loss: {train_loss:.4f}\")\n",
    "print(f\"Validation loss: {val_loss:.4f}\")\n",
    "print(f\"Test loss: {test_loss:.4f}\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb1a95f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier_simple(\n",
    "\tmodel, train_loader, val_loader, optimizer, device,\n",
    "\tnum_epochs, eval_freq, eval_iter\n",
    "):\n",
    "\ttrain_losses, val_losses, train_accs, val_accs = [], [], [], []\n",
    "\texamples_seen, global_step = 0, -1\n",
    "\n",
    "\tfor epoch in range(num_epochs):\n",
    "\t\tmodel.train()\n",
    "\t\t\n",
    "\t\tfor input_batch, target_batch in train_loader:\n",
    "\t\t\toptimizer.zero_grad()\n",
    "\t\t\tloss = calc_loss_batch(input_batch, target_batch, model, device)\n",
    "\t\t\tloss.backward()\n",
    "\t\t\toptimizer.step()\n",
    "\n",
    "\t\t\tglobal_step += 1\n",
    "\t\t\texamples_seen += input_batch.shape[0]\n",
    "\t\t\t\n",
    "\t\t\tif global_step % eval_freq == 0:\n",
    "\t\t\t\ttrain_loss, val_loss = evaluate_model(\n",
    "\t\t\t\t\tmodel, train_loader, val_loader, device, eval_iter\n",
    "\t\t\t\t)\n",
    "\t\t\t\ttrain_losses.append(train_loss)\n",
    "\t\t\t\tval_losses.append(val_loss)\n",
    "\n",
    "\t\t\t\tprint(f\"Epoch {epoch+1}/{num_epochs}, Step {global_step}, \"\n",
    "\t\t\t\t\t  f\"Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\t\n",
    "\t\ttrain_accuracy = cal_accuracy_loader(\n",
    "\t\t\ttrain_loader, model, device, num_batches=eval_iter\n",
    "\t\t)\n",
    "\t\tval_accuracy = cal_accuracy_loader(\n",
    "\t\t\tval_loader, model, device, num_batches=eval_iter\n",
    "\t\t)\n",
    "\n",
    "\t\tprint(f\"Train Accuracy: {train_accuracy*100:.2f}%, Val Accuracy: {val_accuracy*100:.2f}%\")\n",
    "\t\t\n",
    "\t\ttrain_accs.append(train_accuracy)\n",
    "\t\tval_accs.append(val_accuracy)\n",
    "\n",
    "\treturn train_losses, val_losses, train_accs, val_accs, examples_seen\n",
    "\t\n",
    "\n",
    "def evaluate_model(model, train_loader, val_loader, device, eval_iter):\n",
    "\tmodel.eval()\n",
    "\twith torch.no_grad():\n",
    "\t\ttrain_loss = calc_loss_loader(train_loader, model, device, num_batches=eval_iter)\n",
    "\t\tval_loss = calc_loss_loader(val_loader, model, device, num_batches=eval_iter)\n",
    "\t\t\n",
    "\tmodel.train()\n",
    "\treturn train_loss, val_loss\n",
    "\t\n",
    "\t\n",
    "\t\n",
    "\t\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a25d4b29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Step 0, Train Loss: 2.1552, Val Loss: 2.3930\n",
      "Epoch 1/5, Step 50, Train Loss: 0.6114, Val Loss: 0.6328\n",
      "Epoch 1/5, Step 100, Train Loss: 0.5207, Val Loss: 0.5540\n",
      "Train Accuracy: 70.00%, Val Accuracy: 72.50%\n",
      "Validation Accuracy: 72.50%\n",
      "Epoch 2/5, Step 150, Train Loss: 0.5584, Val Loss: 0.4844\n",
      "Epoch 2/5, Step 200, Train Loss: 0.4193, Val Loss: 0.3934\n",
      "Epoch 2/5, Step 250, Train Loss: 0.4077, Val Loss: 0.3506\n",
      "Train Accuracy: 82.50%, Val Accuracy: 85.00%\n",
      "Validation Accuracy: 85.00%\n",
      "Epoch 3/5, Step 300, Train Loss: 0.3390, Val Loss: 0.3159\n",
      "Epoch 3/5, Step 350, Train Loss: 0.3452, Val Loss: 0.3135\n",
      "Train Accuracy: 82.50%, Val Accuracy: 85.00%\n",
      "Validation Accuracy: 85.00%\n",
      "Epoch 4/5, Step 400, Train Loss: 0.2682, Val Loss: 0.3103\n",
      "Epoch 4/5, Step 450, Train Loss: 0.3571, Val Loss: 0.2982\n",
      "Epoch 4/5, Step 500, Train Loss: 0.3403, Val Loss: 0.3265\n",
      "Train Accuracy: 90.00%, Val Accuracy: 85.00%\n",
      "Validation Accuracy: 85.00%\n",
      "Epoch 5/5, Step 550, Train Loss: 0.2861, Val Loss: 0.2664\n",
      "Epoch 5/5, Step 600, Train Loss: 0.2560, Val Loss: 0.1169\n",
      "Train Accuracy: 100.00%, Val Accuracy: 95.00%\n",
      "Validation Accuracy: 95.00%\n",
      "Training time: 4.26 minutes\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "torch.manual_seed(123)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "num_epochs = 5\n",
    "\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
    "\tmodel, train_loader, val_loader, optimizer, device, num_epochs, 50, 5\n",
    ")\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "print(f\"Training time: {(end_time - start_time) / 60:.2f} minutes\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ef8a82ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_values(epochs_seen, examples_seen, train_values, val_values, label=\"loss\"):\n",
    "    fig, ax1 = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "    # Plot training and validation loss against epochs\n",
    "    ax1.plot(epochs_seen, train_values, label=f\"Training {label}\")\n",
    "    ax1.plot(epochs_seen, val_values, linestyle=\"-.\", label=f\"Validation {label}\")\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(label.capitalize())\n",
    "    ax1.legend()\n",
    "\n",
    "    # Create a second x-axis for examples seen\n",
    "    ax2 = ax1.twiny()  # Create a second x-axis that shares the same y-axis\n",
    "    ax2.plot(examples_seen, train_values, alpha=0)  # Invisible plot for aligning ticks\n",
    "    ax2.set_xlabel(\"Examples seen\")\n",
    "\n",
    "    fig.tight_layout()  # Adjust layout to make room\n",
    "    plt.savefig(f\"{label}-plot.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "epochs_tensor = torch.linspace(0, num_epochs, len(train_losses))\n",
    "examples_seen_tensor = torch.linspace(0, examples_seen, len(train_losses))\n",
    "\n",
    "plot_values(epochs_tensor, examples_seen_tensor, train_losses, val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "be941467",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Step 0, Train Loss: 1.6117, Val Loss: 0.4669\n",
      "Epoch 1/5, Step 50, Train Loss: 0.0267, Val Loss: 0.0539\n",
      "Epoch 1/5, Step 100, Train Loss: 0.4016, Val Loss: 0.5039\n",
      "Train Accuracy: 95.00%, Val Accuracy: 97.50%\n",
      "Validation Accuracy: 97.50%\n",
      "Epoch 2/5, Step 150, Train Loss: 0.0155, Val Loss: 0.1055\n",
      "Epoch 2/5, Step 200, Train Loss: 0.1680, Val Loss: 0.0129\n",
      "Epoch 2/5, Step 250, Train Loss: 0.0661, Val Loss: 0.2127\n",
      "Train Accuracy: 100.00%, Val Accuracy: 100.00%\n",
      "Validation Accuracy: 100.00%\n",
      "Epoch 3/5, Step 300, Train Loss: 0.1624, Val Loss: 0.0652\n",
      "Epoch 3/5, Step 350, Train Loss: 0.0088, Val Loss: 0.0920\n",
      "Train Accuracy: 100.00%, Val Accuracy: 100.00%\n",
      "Validation Accuracy: 100.00%\n",
      "Epoch 4/5, Step 400, Train Loss: 0.1166, Val Loss: 0.0073\n",
      "Epoch 4/5, Step 450, Train Loss: 0.0016, Val Loss: 0.0019\n",
      "Epoch 4/5, Step 500, Train Loss: 0.0015, Val Loss: 0.0210\n",
      "Train Accuracy: 100.00%, Val Accuracy: 100.00%\n",
      "Validation Accuracy: 100.00%\n",
      "Epoch 5/5, Step 550, Train Loss: 0.0032, Val Loss: 0.0064\n",
      "Epoch 5/5, Step 600, Train Loss: 0.0019, Val Loss: 0.0037\n",
      "Train Accuracy: 100.00%, Val Accuracy: 100.00%\n",
      "Validation Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "## Trying to fine-tune the entire model\n",
    "for param in model.parameters():\n",
    "\tparam.requires_grad = True\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5, weight_decay=0.1)\n",
    "num_epochs = 5\n",
    "\n",
    "train_losses, val_losses, train_accs, val_accs, examples_seen = train_classifier_simple(\n",
    "\tmodel, train_loader, val_loader, optimizer, device, num_epochs, 50, 5\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0383a363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 99.71%\n",
      "Validation accuracy: 99.31%\n",
      "Test accuracy: 97.97%\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = cal_accuracy_loader(\n",
    "\ttrain_loader, model, device\n",
    ")\n",
    "val_accuracy = cal_accuracy_loader(\n",
    "\tval_loader, model, device\n",
    ")\n",
    "test_accuracy = cal_accuracy_loader(\n",
    "\ttest_loader, model, device\n",
    ")\n",
    "\n",
    "print(f\"Train accuracy: {train_accuracy*100:.2f}%\")\n",
    "print(f\"Validation accuracy: {val_accuracy*100:.2f}%\")\n",
    "print(f\"Test accuracy: {test_accuracy*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "72b41ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_review(\n",
    "\ttext, model, tokenizer, device, max_length=None,\n",
    "\tpad_token_id=50256\n",
    "):\n",
    "\tmodel.eval()\n",
    "\t\n",
    "\tinput_ids = tokenizer.encode(text)\n",
    "\tsupported_context_length = model.pos_emb.weight.shape[0]\n",
    "\n",
    "\tinput_ids = input_ids[:min(max_length, supported_context_length)]\n",
    "\tinput_ids += [pad_token_id] * (max_length - len(input_ids))\n",
    "\t\n",
    "\tinput_tensor = torch.tensor(input_ids, device=device).unsqueeze(0)\n",
    "\n",
    "\twith torch.no_grad():\n",
    "\t\tlogits = model(input_tensor)[:, -1, :]\n",
    "\tpredicted_class = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "\treturn \"spam\" if predicted_class == 1 else \"not spam\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "84d5e9ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n"
     ]
    }
   ],
   "source": [
    "text_1 = (\n",
    "    \"You are a winner you have been specially\"\n",
    "    \" selected to receive $1000 cash or a $2000 award.\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_1, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a6e5d279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not spam\n"
     ]
    }
   ],
   "source": [
    "text_2 = (\n",
    "    \"Hey, just wanted to check if we're still on\"\n",
    "    \" for dinner tonight? Let me know!\"\n",
    ")\n",
    "\n",
    "print(classify_review(\n",
    "    text_2, model, tokenizer, device, max_length=train_dataset.max_length\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0858465e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"review_classifier.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30096ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
